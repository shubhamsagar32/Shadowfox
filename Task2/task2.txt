### Tabulating the results

from tabulate import tabulate

### Remove unnecessary warnings

import warnings
warnings.filterwarnings('ignore')


dataset = pd.read_csv('Car_sales.csv')


dataset.head(10)


dataset.shape
(157, 16)


dataset.info()

dataset.Manufacturer = dataset.Manufacturer.astype('category')
dataset.Model = dataset.Model.astype('category')
dataset.Vehicle_type = dataset.Vehicle_type.astype('category')



dataset.info()



missingno.matrix(dataset)

dataset.describe()


manufacturer_count = dataset['Manufacturer'].value_counts(dropna = False)


plt.figure(figsize = (20, 6))
sns.barplot(manufacturer_count.index, manufacturer_count.values, alpha = 0.8)
plt.title('Bar graph showing the value counts of the column - Manufacturer')
plt.ylabel('Number of Occurrences', fontsize = 12)
plt.xlabel('Manufacturer', fontsize = 12)
plt.show()


mean_price_manufacturer = dataset[['Manufacturer', 'Price_in_thousands']].groupby('Manufacturer', as_index = False).mean()
mean_price_manufacturer



plt.figure(figsize = (20, 6))
sns.barplot(mean_price_manufacturer['Manufacturer'], mean_price_manufacturer['Price_in_thousands'], alpha = 0.8)
plt.title('Mean Sales Price for each Manufacturer')
plt.ylabel('Mean Price', fontsize = 12)
plt.xlabel('Manufacturer', fontsize = 12)
plt.show()



vehicle_count = dataset['Vehicle_type'].value_counts(dropna = False)
vehicle_count


sns.barplot(vehicle_count.index, vehicle_count.values, alpha = 0.8)
plt.title('Bar graph showing the value counts of the column - Vehicle type')
plt.ylabel('Number of Occurrences', fontsize = 12)
plt.xlabel('Vehicle type', fontsize = 12)
plt.show()


mean_price_vehicle = dataset[['Vehicle_type', 'Price_in_thousands']].groupby('Vehicle_type', as_index = False).mean()
mean_price_vehicle


sns.barplot(mean_price_vehicle['Vehicle_type'], mean_price_vehicle['Price_in_thousands'], alpha = 0.8)
plt.title('Mean Sales Price for each Vehicle type')
plt.ylabel('Mean Price', fontsize = 12)
plt.xlabel('Vehicle type', fontsize = 12)
plt.show()



sns.distplot(dataset['Sales_in_thousands'], label = 'Skewness: %.2f'%(dataset['Sales_in_thousands'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Sales in thousands')
Text(0.5, 1.0, 'Distribution of the column - Sales in thousands')


sns.distplot(dataset['__year_resale_value'], label = 'Skewness: %.2f'%(dataset['__year_resale_value'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - __year_resale_value')
Text(0.5, 1.0, 'Distribution of the column - __year_resale_value')


sns.distplot(dataset['Price_in_thousands'], label = 'Skewness: %.2f'%(dataset['Price_in_thousands'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Price_in_thousands')
Text(0.5, 1.0, 'Distribution of the column - Price_in_thousands')



sns.distplot(dataset['Engine_size'], label = 'Skewness: %.2f'%(dataset['Engine_size'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Engine_size')
Text(0.5, 1.0, 'Distribution of the column - Engine_size')



sns.distplot(dataset['Horsepower'], label = 'Skewness: %.2f'%(dataset['Horsepower'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Horsepower')
Text(0.5, 1.0, 'Distribution of the column - Horsepower')


sns.distplot(dataset['Wheelbase'], label = 'Skewness: %.2f'%(dataset['Wheelbase'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Wheelbase')
Text(0.5, 1.0, 'Distribution of the column - Wheelbase')


sns.distplot(dataset['Width'], label = 'Skewness: %.2f'%(dataset['Width'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Width')
Text(0.5, 1.0, 'Distribution of the column - Width')


sns.distplot(dataset['Length'], label = 'Skewness: %.2f'%(dataset['Length'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Length')
Text(0.5, 1.0, 'Distribution of the column - Length')


sns.distplot(dataset['Curb_weight'], label = 'Skewness: %.2f'%(dataset['Curb_weight'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Curb_weight')
Text(0.5, 1.0, 'Distribution of the column - Curb_weight')



sns.distplot(dataset['Fuel_capacity'], label = 'Skewness: %.2f'%(dataset['Fuel_capacity'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Fuel_capacity')
Text(0.5, 1.0, 'Distribution of the column - Fuel_capacity')



sns.distplot(dataset['Fuel_efficiency'], label = 'Skewness: %.2f'%(dataset['Fuel_efficiency'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Fuel_efficiency')
Text(0.5, 1.0, 'Distribution of the column - Fuel_efficiency')


sns.distplot(dataset['Power_perf_factor'], label = 'Skewness: %.2f'%(dataset['Power_perf_factor'].skew()))
plt.legend(loc = 'best')
plt.title('Distribution of the column - Power_perf_factor')
Text(0.5, 1.0, 'Distribution of the column - Power_perf_factor')



def detect_outliers(df, n, features_list):
    outlier_indices = [] 
    for feature in features_list: 
        Q1 = np.percentile(df[feature], 25)
        Q3 = np.percentile(df[feature], 75)
        IQR = Q3 - Q1
        outlier_step = 1.5 * IQR 
        outlier_list_col = df[(df[feature] < Q1 - outlier_step) | (df[feature] > Q3 + outlier_step)].index
        outlier_indices.extend(outlier_list_col) 
    outlier_indices = Counter(outlier_indices)
    multiple_outliers = list(key for key, value in outlier_indices.items() if value > n) 
    return multiple_outliers

outliers_to_drop = detect_outliers(dataset, 2, ['Sales_in_thousands', '__year_resale_value', 'Price_in_thousands', 
                                               'Engine_size', 'Horsepower', 'Wheelbase', 'Width', 'Length', 'Curb_weight',
                                               'Fuel_capacity', 'Fuel_efficiency', 'Power_perf_factor'])
print("We will drop these {} indices: ".format(len(outliers_to_drop)), outliers_to_drop)


modified_dataset = dataset[dataset['Price_in_thousands'].notna()]
modified_dataset


modified_dataset.isnull().sum().sort_values(ascending = False)


year_index = list(~modified_dataset['__year_resale_value'].isnull())
median_year = np.median(modified_dataset['__year_resale_value'].loc[year_index])
median_year


modified_dataset['__year_resale_value'].fillna(median_year, inplace = True)


modified_dataset['__year_resale_value'].isnull().sum()


fuel_index = list(~modified_dataset['Fuel_efficiency'].isnull())
median_fuel = np.median(modified_dataset['Fuel_efficiency'].loc[fuel_index])
median_fuel


modified_dataset['Fuel_efficiency'].fillna(median_year, inplace = True)